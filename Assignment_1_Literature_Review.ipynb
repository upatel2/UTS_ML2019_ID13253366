{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/upatel2/UTS_ML2019_ID13253366/blob/master/Assignment_1_Literature_Review.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iO-8JeJEs0D",
        "colab_type": "text"
      },
      "source": [
        "# Machine learning Assignment 1. \n",
        "\n",
        "Literature Review – Machine Learning – 31005 – “The Computational Complexity of Probabilistic Inference Using Bayesian Belief Networks”. \n",
        "\n",
        "> > > > ### **ML_31005_A1_13253366_Utsav_Patel**\n",
        "\n",
        "The link to my Github file is: \n",
        "*https://github.com/upatel2/UTS_ML2019_ID13253366/blob/master/Assignment_1_Literature_Review.ipynb*\n",
        " \n",
        "## **Abstract**\n",
        "\n",
        "Bayesian Belief Networks are a statistical model used to describe the dependencies between different variables. These networks have been advancing rapidly and researchers are now starting to explore the uses of these networks in Artificial Intelligence (AI) and Machine Learning. There has been development of specific algorithms for determining inference, however, the majority of general belief networks have escaped the endeavour of inference algorithms. The article emphasises that the probabilistic inference using belief networks is NP-hard. \n",
        "\n",
        "## **1.Introduction**\n",
        "\n",
        "The vast field of Artificial Intelligence has various classical systems that use a directed graph to represent relationships among events. Gregory F. Cooper explains a newly created model named as the “Bayesian Belief Network” [2], also termed as the probabilistic casual network [3], which is extensively researched today. These networks portray probabilistic relationships effectively. The tendency to assume variables are dependent on other variables is neglected by the requirement to consider only known dependencies amongst other variables [3].\n",
        "One of the main positives of the network is that it expresses the probabilistic relationships comprehensively. This advantage has accounted for the creation of new professional systems that use belief networks for data analysis. Multiply connected belief networks have at least one pair of nodes that contain an undirected path that connects them, whereas a single connected network has no nodes that have more than one undirected path between them. This article paper aims to show that the probabilistic inference using multiply connected networks are NP-hard, hence implying that an efficient algorithm cannot be created for these networks. In the remaining section of the paper, we discuss that the proof of problem being NP-hard enables us to favor the design of a special-case approximation algorithm. Finally, the paper is concluded through the study of the significance of this result in terms of future scope for belief networks.\n",
        "\n",
        "## **2.Content**\n",
        "\n",
        "Gregory F. Cooper, in his research paper, expresses the use of Bayesian belief networks and how they are useful for representing probabilistic dependencies amongst variables. The author explains the development for several algorithms for more effective probabilistic inferencing; however, the article attempts to show that inference through belief networks is NP-hard. Thus, research needs to be done in perspective of developing unique algorithms. The joint probability of instantiation of all n variables is calculated through equations. Hence, the joint probability can be computed as the product of only n probabilities. Through such equations and further study of the casual relationships, Cooper confirms that belief networks can represent casual relationships, but they cannot have casual interpretations. Generally, a belief network greatly reduces the number of probabilities that must be assessed and stored. To prove that the problem is NP-hard, we transform a NP-problem known as 3-satisfiability (3SAT) [4, 5] to a decision-problem version of probabilistic inference problem using Belief Networks (PIBNETD). Thus, we show that PIBNET is NP-hard. Several ways can be shown to prove the difficulty level of PIBNET.\n",
        "\n",
        "In this paper, however, we shall use a reduction from 3SAT, because this strategy yields a very simple proof and demonstrates that PIBNET is NP-hard even for belief networks that have significantly restricted topologically. Rosenthai has applied a related reduction using the general satisfiability problem to show that solving fault trees is NP-hard [6]. Finally, by using 3SAT to prove that PIBNET is NP-hard, we can readily derive additional complexity results on belief-network inference.\n",
        "\n",
        "Through the computation of different formulas and belief network testing, Cooper proved that PIBNET is NP-hard since it can be easily made to PIBNET by returning “yes” and “no.” Furthermore, in complexity results, the evidence supports PIBNET being NP-hard when the outdegree is maximum five and indegree is maximum three.\n",
        "\n",
        "Therefore, this paper proves that probabilistic inferences using normal belief networks is NP-hard, mainly using multiply connected networks. Hence, the necessity to develop an exact or general should be less prioritized as it will most likely be pointless and the search needs to be shifted towards special-case methods. \n",
        "\n",
        "## **3.Innovation**\n",
        "\n",
        "The paper mainly focuses on the current availability of several algorithms to perform probabilistic inference using multiply connected networks. This paper shows that inference using belief networks is NP-hard. The importance of knowing the NP is crucial since it helps us understand that a normal solution is most likely to be inefficient. Hence, we can instead focus on an algorithm that is more efficient and reliable.\n",
        "\n",
        "During the start of the paper, Cooper tries to explain the development of algorithms for efficient probabilistic inference using belief networks. The paper personifies that the probabilistic inference is NP-hard, but the results, however, suggest that we need to focus on the development of a special-case, average-case and approximation algorithm. A brief summary of a belief network is described by Cooper. He also outlines the types of probabilistic inferences performed on these belief networks which is a new and emerging topic today. Belief networks are composed of a structure augmented by probabilities. They can represent probabilities from a separate sample space with the exception that the probability in that space can be determined from the probabilities in the belief network. This ideology of these networks allows people to study this topic and lead their investigation in the right direction.\n",
        "\n",
        "A new methodology is proved by Cooper as he shows the problem is NP-hard. An NP-complete problem named S3-Satisfiability (3SAT) is transformed to a Decision-problem version of Probabilistic Inference using Belief Networks (PIBNETD). This helps us acquire the complexity results of the networks. This paper defines a new belief-network and emphasizes that PIBNET is NP-hard. Cooper proves that using multiply connected networks with instantiated variables is NP-hard. Although this helps us to avoid the development of a general and exact algorithm, it also shifts the search to the development of a special-case algorithm.\n",
        "\n",
        "Additionally, the paper contributes two new types of special algorithms that can be implemented for further study. One is Approximation algorithm that forms certain bound solutions but contains only the exact solution within the boundaries. The second algorithm is Special-case algorithms which only work for certain special belief-networks.\n",
        "\n",
        "## **4.Technical Quality**\n",
        "\n",
        "The technical development of the research paper was of sound quality. This is because the author can present the evidence through equations to prove that the probabilistic inference using belief networks is NP-hard. Several ways can be correlated to show that PIBNET is NP-hard. Cooper supported this theory through the transformation of an NP-complete problem named 3SAT (as mentioned above) [5,10] to a decision based-problem using belief networks (PIBNETD). The process of transforming the decision-based problem to an NP-complete problem was quite complex and would be significantly difficult to replicate. Cooper could have made the fourth section (Transforming 3SAT to PIBNETD) easier by giving a brief summary of how the equations were used and to outline the steps so it can be replicated by others. Once, the proof of NP-hard was completed, Cooper continues to derive complexity results on inference. However, the Complexity results explained by Cooper is of top quality since it explains the need for the results and how they are extrapolated through equations and also how the results are further used for analysis. It was also proven that the PIBNET needs to have an outdegree of maximum 5 and indegree of almost 3. Then, in the final section of the paper, Cooper writes a high-quality discussion detailing the important features explained in the article. The discussion describes the need to show that inference using belief networks is NP-hard, the inefficiency of multiply-connected networks to be used as they are extremely difficult. Furthermore, the author explains how the proposed Approximation and Special-Case algorithms will be useful for further research in fields like medicine. This explanation is vital for the field of Machine Learning as it will be useful for further exploration.\n",
        "\n",
        "## **5.Application and X-Factor**\n",
        "\n",
        "I found the proposal in the research paper optimistic and helpful in terms of current and further research. This is since Cooper proves that the inference is NP-hard, suggesting the need for research towards the development of average-case, special-case and approximation algorithms. The approximation algorithms [3] do not provide the best solution, but they satisfy their goal of trying to reach the solution as close as possible in a reasonable amount of time. Their application has been further researched by several people, but they seem to be difficult to solve, hence are unsuccessful at finding the optimal solutions for high scale uses. Although, their ability to bound a probability form P (x | Z), has invoked the requirement to address domains like medicine [6]. A similar method used Monte Carlo techniques to substitute the current decision-making algorithms. The special-case algorithms though have been researched well and can be used for further applications as they are computationally tractable. The study of Bayesian networks is also relatively young, which emphasizes for it to be extensively researched. They were used conventionally for encoding in expert systems. However, due to the rise of large amounts of data in applications, more insistence has been given to the need to research these networks. An easy way of combining knowledge with data is one major advantage of such networks. The discussion of this topic seems to be significant in terms of allowing researchers to lead the investigation of developing a special algorithm. This work can be helpful in the fields of Artificial Intelligence and Machine Learning since they are built from probability calculations. It can be used for decision making, modeling distributions and identifying relationships between domains.\n",
        "\n",
        "## **6.Presentation**\n",
        "\n",
        "The quality of the paper is quite high. This is because the structure of the paper was presented very well by Gregory F. Cooper. The research paper follows a good sequence which contains all the steps in a systematic manner which allows readers to follow the sequence of the papers’ topics. The author firstly starts with an Abstract, which explains the background of the topic related to Belief networks and addresses the need a special-case algorithm for probabilistic inference. Then is the introduction, in which Cooper justifies the use of Belief networks, Probabilistic Inference and outlines the importance of the problem is NP-hard. The introduction gives a good overall brief regarding this research paper. The next two sections of the paper highlight Belief Networks and Probabilistic Inference, then proves the problem is NP-hard through a wide range of calculations. Thereafter, Cooper outlines the definition of 3SAT and transformation to PIBNETD. The authors then develop additional complexity results which are elucidated through advantages and disadvantages of 3SAT and ultimately ends with a discussion, to sum up the topic of Probabilistic Inference using Bayesian Belief Networks and their complexity. The complexity results are thoroughly explained as they help determine the future of the PIBNET and 3SAT. The topic is argued precisely in terms of what Belief networks are and how Probabilistic Inference is used for them. The only downside is the lack of depth for the future research information and how it would be helpful in other applications. The overall clarity of the paper is of satisfactory quality since it is understandable for readers. The sections that could be refined to make the paper more understandable is the 3SAT problem and its transformation.\n",
        "\n",
        "## **7.References**\n",
        "\n",
        "[1] Cooper, G. (1990). The computational complexity of probabilistic inference using Bayesian belief networks. Artificial Intelligence, 42(2-3), pp.393-405. \n",
        "\n",
        "[2] J. Pearl, Fusion, propagation, and structuring in belief networks, Artificial Intelligence 29 (1986) 241-288. \n",
        "\n",
        "[3] [11] G.F. Cooper, NESTOR: A computer-based medical diagnostic aid that integrates causal and probabilistic knowledge, Ph.D. Dissertation, Stanford University, Stanford, CA (1984).\n",
        "\n",
        "[4] S.A. Cook, The complexity of theorem-proving procedures, in: Proceedings Third Annual ACM Symposium on Theory of Computing, New York (1971) 151-158.\n",
        "\n",
        "[5] M.R. Garey and D.S. Johnson, Computers and Intractability: A Guide to the Theory of NP-Completeness (Freeman, New York, 1979). \n",
        "\n",
        "[6] H.E. Pople Jr, Heuristic methods for imposing structure on ill-structured problems: The structuring of medical diagnostics, in: P. Szolovits, ed., Artificial Intelligence in Medicine (Westview Press, Boulder, CO, 1982) 119-190 \n",
        "\n",
        "[7] Cross Validated. (2015). When to use Bayesian Networks over other machine learning approaches? [online] Available at: https://stats.stackexchange.com/questions/139728/when-to-use-bayesian-networks-over-other-machine-learning-approaches [Accessed 27 Aug. 2019]. \n",
        "\n",
        "[8] Goyal, P. (2017). What does Bayesian networks mean in Machine Learning? [online] Quora.com. Available at: https://www.quora.com/What-does-Bayesian-networks-mean-in-Machine-Learning [Accessed 27 Aug. 2019]. \n",
        "\n",
        "[9] Golmard, J. (1993). PROBABILISTIC INFERENCE IN ARTIFICIAL INTELLIGENCE: THE METHOD OF BAYESIAN NETWORKS. Philosophy of Probability, pp.257-291.\n",
        "\n",
        "[10] Guo, H. and Hsu, W. (2002). A Survey of Algorithms for Real-Time Bayesian Network Inference. Department of Computing and Information Sciences, Kansas State University. \n",
        "\n",
        "[11] R.M. Chavez and G.F. Cooper, KNET: Integrating hypermedia and normative Bayesian modeling, in: Proceedings Workshop on Uncertainty in Artificial Intelligence, Minneapolis, MN (1988). \n"
      ]
    }
  ]
}